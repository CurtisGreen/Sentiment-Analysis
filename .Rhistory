}
warnings()
wcount
wcount = count(per_tweet_freq$word[condition])
wcount
wcount$freq
pert_tweet_freq[condition] = wcount$freq
per_tweet_freq[condition] = wcount$freq
per_tweet_freq$word_per_tweet = 0
pert_tweet_freq$word_per_tweet[condition]
per_tweet_freq$word_per_tweet[condition]
per_tweet_freq$word_per_tweet[condition] = wcount$freq
per_tweet_freq$word_per_tweet[condition]
for (row in 1:nrow(per_tweet_freq)){
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
per_tweet_freq$word_per_tweet[condition] = wcount$freq
}
warnings()
length(wcount$freq)
dim(per_tweet_freq)
dim(per_tweet_freq)[1]
while (row <= dim(per_tweet_freq)[1]){
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
per_tweet_freq$word_per_tweet[condition] = wcount$freq
row = row + length(wcount$freq)
}
warnings()
while (row <= dim(per_tweet_freq)[1]){
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
per_tweet_freq$word_per_tweet[condition] = wcount$freq
row = row + length(wcount$freq)
row
}
row = 1
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
per_tweet_freq$word_per_tweet[condition] = wcount$freq
row = row + length(wcount$freq)
row
row
row = 1
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
condition
wcount = count(per_tweet_freq$word[condition])
wcount
wcount$freq
per_tweet_freq$word_per_tweet[condition]
per_tweet_freq$word[condition]
natural_join(per_tweet_freq$word_per_tweet[condition], wcount$freq)
inner_join(per_tweet_freq$word_per_tweet[condition], wcount$freq)
inner_join(per_tweet_freq$word_per_tweet[condition], wcount$freq, by = "word")
per_tweet_freq$word_per_tweet[condition]
per_tweet_freq[condition]
wcount
count_condition = per_tweet_freq$word == wcount$x
per_tweet_freq$word_per_tweet[condition & count_condition]
per_tweet_freq$word_per_tweet[condition & count_condition]
per_tweet_freq$word_per_tweet[condition & count_condition]
per_tweet_freq$word_per_tweet[condition & count_condition]
per_tweet_freq$word_per_tweet[condition & count_condition]
per_tweet_freq$word_per_tweet[condition & count_condition]
per_tweet_freq$word_per_tweet[condition & count_condition]
per_tweet_freq$word_per_tweet[condition & count_condition]
count_condition
per_tweet_freq[condition,]
per_tweet_freq = parsed_tweets
per_tweet_freq$word_per_tweet = 0
row = 1
temp_merge = inner_join(per_tweet_freq[condition,], wcount)
temp_merge = inner_join(per_tweet_freq[condition,], wcount, by = c("word", "x"))
wcount
colnames(wcount)[1] = word
colnames(wcount)[1] = "word"
temp_merge = inner_join(per_tweet_freq[condition,], wcount)
View(temp_merge)
View(data)
View(parsed_tweets)
row = row + length(wcount$freq)
row
tf_words = parsed_tweets
per_tweet_freq = parsed_tweets
per_tweet_freq$word_per_tweet = 0
row = 1
while (row <= dim(per_tweet_freq)[1]){
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(per_tweet_freq[condition,], wcount)
per_tweet_freq$word_per_tweet[condition] = wcount$freq
row = row + length(per_tweet_freq$word[condition])
}
warnings()
tf_words = parsed_tweets
per_tweet_freq = parsed_tweets
per_tweet_freq$word_per_tweet = 0
row = 1
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(per_tweet_freq[condition,], wcount, by = "word")
per_tweet_freq$word_per_tweet[condition] = wcount$freq
row = row + length(per_tweet_freq$word[condition])
row
tf_words = parsed_tweets
per_tweet_freq = parsed_tweets
row = 1
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(per_tweet_freq[condition,], wcount, by = "word")
per_tweet_freq$word_per_tweet[condition] = temp_merge$freq
row = row + length(per_tweet_freq$word[condition])
tf_words = parsed_tweets
per_tweet_freq = parsed_tweets
row = 1
while (row <= dim(per_tweet_freq)[1]){
condition = per_tweet_freq$index == per_tweet_freq[row,]$index
wcount = count(per_tweet_freq$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(per_tweet_freq[condition,], wcount, by = "word")
per_tweet_freq$word_per_tweet[condition] = temp_merge$freq
row = row + length(per_tweet_freq$word[condition])
}
tf_words = tf_words[!duplicated(tf_words$word),]
tf_words$emotion[tf_words$emotion == "Negative emotion"] = 0
tf_words$emotion[tf_words$emotion == "Positive emotion"] = 1
freq = as.data.frame(table(parsed_tweets$word))
colnames(freq)[1] = "word"
tf_IDF = as.data.frame(left_join(tf_words, freq, by = "word"))
num_words = dim(tf_words)[1]
IDF_words = parsed_tweets
IDF_words
IDF_words = IDF_words[!duplicated(IDF_words$word),]
IDF_words$emotion[IDF_words$emotion == "Negative emotion"] = 0
IDF_words$emotion[IDF_words$emotion == "Positive emotion"] = 1
freq = as.data.frame(table(parsed_tweets$word))
colnames(freq)[1] = "word"
IDF = as.data.frame(left_join(IDF_words, freq, by = "word"))
num_words = dim(IDF_words)[1]
View(IDF_words)
View(IDF_words)
View(IDF_words)
View(IDF)
test = right_join(IDF, per_tweet_freq, by = "word")
View(test)
IDF_words = parsed_tweets
TF_words = parsed_tweets
row = 1
while (row <= dim(TF_words)[1]){
condition = TF_words$index == TF_words[row,]$index
wcount = count(TF_words$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(TF_words[condition,], wcount, by = "word")
TF_words$count_per_tweet[condition] = temp_merge$freq
this_length = length(TF_words$word[condition])
TF_words$num_words[condition] = this_length
row = row + this_length
}
View(TF_words)
IDF_words = IDF_words[!duplicated(IDF_words$word),]
IDF_words$emotion[IDF_words$emotion == "Negative emotion"] = 0
IDF_words$emotion[IDF_words$emotion == "Positive emotion"] = 1
freq = as.data.frame(table(parsed_tweets$word))
colnames(freq)[1] = "word"
IDF = as.data.frame(left_join(IDF_words, freq, by = "word"))
num_words = dim(IDF_words)[1]
right_join(TF_words, IDF, by = "word")
test = right_join(TF_words, IDF, by = "word")
View(test)
View(test)
num_words = dim(data)[1]
View(test)
IDF_words = parsed_tweets
TF_words = parsed_tweets
row = 1
while (row <= dim(TF_words)[1]){
condition = TF_words$index == TF_words[row,]$index
wcount = count(TF_words$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(TF_words[condition,], wcount, by = "word")
TF_words$count_per_tweet[condition] = temp_merge$freq
this_length = length(TF_words$word[condition])
TF_words$num_words[condition] = this_length
row = row + this_length
}
IDF_words = IDF_words[!duplicated(IDF_words$word),]
IDF_words$emotion[IDF_words$emotion == "Negative emotion"] = 0
IDF_words$emotion[IDF_words$emotion == "Positive emotion"] = 1
freq = as.data.frame(table(parsed_tweets$word))
colnames(freq)[1] = "word"
IDF = as.data.frame(left_join(IDF_words, freq, by = "word"))
num_tweets = dim(data)[1]
TF_IDF_temp = right_join(TF_words, IDF, by = "word")
TF_IDF$index = TF_IDF_temp$index.x
TF_IDF$emotion = TF_IDF_temp$emotion.y
TF_IDF$word = TF_IDF$word
TF_IDF$TF = (TF_IDF_temp$count_per_tweet/TF_IDF_temp$num_words)
TF_IDF = TF_IDF_temp
TF_IDF$index = TF_IDF_temp$index.x
TF_IDF$emotion = TF_IDF_temp$emotion.y
TF_IDF$word = TF_IDF$word
TF_IDF$TF = (TF_IDF_temp$count_per_tweet/TF_IDF_temp$num_words)
TF_IDF$IDF = log(num_tweets/TF_IDF$Freq)
nrc = get_sentiments("nrc") %>%
filter(sentiment %in% c("positive",
"negative"))
View(tf_IDF)
View(TF_IDF)
TF_IDF = cbind.data.frame(TF_IDF_temp$index.x, TF_IDF_temp$emotion.y, TF_IDF$word)
colnames(TF_IDF) = c("index", "emotion", "word")
TF_IDF$TF = (TF_IDF_temp$count_per_tweet/TF_IDF_temp$num_words)
TF_IDF$IDF = log(num_tweets/TF_IDF$Freq)
TF_IDF$IDF = log(num_tweets/TF_IDF_temp$Freq)
median(TF_IDF$IDF)
median(TF_IDF$TF)
median(TF_IDF$TF*TF_IDF$IDF)
mean(TF_IDF$TF*TF_IDF$IDF)
5.4*.04
3.5*.04
3.5*.03
TF_IDF$TF_IDF = TF_IDF$TF * TF_IDF$IDF
test = TF_IDF[TF_IDF$TF_IDF > 0,]
test = TF_IDF[TF_IDF$IDF > .05,]
test = TF_IDF[TF_IDF$IDF > .5,]
test = TF_IDF[TF_IDF$IDF > 4,]
mean(TF_IDF$IDF)
median(TF_IDF$IDF)
test = TF_IDF[TF_IDF$IDF > 3.37,]
View(TF_IDF_temp)
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"] = 0
TF_IDF$emotion[TF_IDF$emotion == "Positive emotion"] = 1
freq = as.data.frame(table(parsed_tweets$word))
colnames(freq)[1] = "word"
IDF = as.data.frame(left_join(IDF_words, freq, by = "word"))
num_tweets = dim(data)[1]
TF_IDF_temp = right_join(TF_words, IDF, by = "word")
TF_IDF = TF_IDF_temp
TF_IDF = cbind.data.frame(TF_IDF_temp$index.x, TF_IDF_temp$emotion.x, TF_IDF$word)
colnames(TF_IDF) = c("index", "emotion", "word")
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"] = 0
IDF_words = parsed_tweets
TF_words = parsed_tweets
row = 1
while (row <= dim(TF_words)[1]){
condition = TF_words$index == TF_words[row,]$index
wcount = count(TF_words$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(TF_words[condition,], wcount, by = "word")
TF_words$count_per_tweet[condition] = temp_merge$freq
this_length = length(TF_words$word[condition])
TF_words$num_words[condition] = this_length
row = row + this_length
}
IDF_words = IDF_words[!duplicated(IDF_words$word),]
freq = as.data.frame(table(parsed_tweets$word))
colnames(freq)[1] = "word"
IDF = as.data.frame(left_join(IDF_words, freq, by = "word"))
num_tweets = dim(data)[1]
TF_IDF_temp = right_join(TF_words, IDF, by = "word")
TF_IDF = TF_IDF_temp
TF_IDF = cbind.data.frame(TF_IDF_temp$index.x, TF_IDF_temp$emotion.x, TF_IDF$word)
colnames(TF_IDF) = c("index", "emotion", "word")
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"] = 0
TF_IDF$emotion[TF_IDF$emotion == "Positive emotion"] = 1
TF_IDF = cbind.data.frame(TF_IDF_temp$index.x, TF_IDF_temp$emotion.x, TF_IDF$word)
colnames(TF_IDF) = c("index", "emotion", "word")
TF_IDF$emotion == "Negative emotion"
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"]
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"] = 0
TF_IDF = cbind(TF_IDF_temp$index.x, TF_IDF_temp$emotion.x, TF_IDF$word)
colnames(TF_IDF) = c("index", "emotion", "word")
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"] = 0
TF_IDF = cbind.data.frame(TF_IDF_temp$index.x, TF_IDF_temp$emotion.x, TF_IDF$word, stringsAsFactors = FALSE)
TF_IDF = cbind.data.frame(TF_IDF_temp$index.x, TF_IDF_temp$emotion.x, TF_IDF_temp$word, stringsAsFactors = FALSE)
colnames(TF_IDF) = c("index", "emotion", "word")
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"] = 0
TF_IDF$emotion[TF_IDF$emotion == "Positive emotion"] = 1
TF_IDF$TF = (TF_IDF_temp$count_per_tweet/TF_IDF_temp$num_words)
TF_IDF$IDF = log(num_tweets/TF_IDF_temp$Freq)
TF_IDF$TF_IDF = TF_IDF$TF * TF_IDF$IDF
test = TF_IDF[TF_IDF$IDF > 3.37,]
weighted_model = TF_IDF %>%
group_by(index = index %/% 1) %>%
summarise(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
View(weighted_model)
weighted_model = TF_IDF %>%
group_by(index = as.factor(index) %/% 1) %>%
summarise(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF %>%
group_by(index = as.numeric(index) %/% 1) %>%
summarise(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
View(weighted_model)
weighted_model = TF_IDF %>%
group_by(index = as.numeric(index) %/% 1) %>%
summarise(TF = sum(TF), IDF = sum(IDF))
weighted_model = TF_IDF %>%
group_by(index = index %/% 2) %>%
summarise(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF %>%
group_by(index = index %/% 1) %>%
summarise(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(index = index %/% 1) %>%
summarise(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = weighted_model %>%
group_by(index = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(index = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
library(dplyr)
library("dbplyr", lib.loc="~/R/win-library/3.4")
detach("package:dbplyr", unload=TRUE)
weighted_model = weighted_model %>%
group_by(index = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(index = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
summarize?
?summarize
library(plyr)
weighted_model = weighted_model %>%
group_by(index = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(index = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(index, index) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(test = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
View(word_count)
weighted_model = weighted_model %>%
group_by(index) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(index) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = weighted_model %>%
group_by(index)
weighted_model = TF_IDF
weighted_model = weighted_model %>%
group_by(index)
weighted_model %>%
group_by(index)
weighted_model = TF_IDF
head(TF_IDF)
weighted_model = TF_IDF[order(index)]
TF_IDF$index = as.numeric(TF_IDF$index)
weighted_model = TF_IDF[order(index)]
weighted_model = TF_IDF[sort(index)]
weighted_model = TF_IDF[order(index),]
weighted_model = TF_IDF[order(TF_IDF$index), ]
weighted_model = weighted_model %>%
group_by(test = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
weighted_model = TF_IDF[order(TF_IDF$index), ]
View(weighted_model)
View(weighted_model)
ddply(weighted_model, "index", function(x) sum(x[-1]))
weighted_model = as.data.frame(TF_IDF[order(TF_IDF$index), ])
weighted_model = weighted_model %>%
group_by(test = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
source('C:/Users/Curtis/Documents/R/Data Mining/Sentiment-Analysis/SentimentAnalysis.R')
source('C:/Users/Curtis/Documents/R/Data Mining/Sentiment-Analysis/SentimentAnalysis.R')
source('C:/Users/Curtis/Documents/R/Data Mining/Sentiment-Analysis/SentimentAnalysis.R', echo=TRUE)
condition = TF_words$index == TF_words[row,]$index
wcount = count(TF_words$word[condition])
?count
library(dplyr)
wcount = count(TF_words$word[condition])
library(plyr)
wcount = count(TF_words$word[condition])
IDF_words = parsed_tweets
TF_words = parsed_tweets
row = 1
while (row <= dim(TF_words)[1]){
condition = TF_words$index == TF_words[row,]$index
wcount = count(TF_words$word[condition])
colnames(wcount)[1] = "word"
temp_merge = inner_join(TF_words[condition,], wcount, by = "word")
TF_words$count_per_tweet[condition] = temp_merge$freq
this_length = length(TF_words$word[condition])
TF_words$num_words[condition] = this_length
row = row + this_length
}
IDF_words = IDF_words[!duplicated(IDF_words$word),]
freq = as.data.frame(table(parsed_tweets$word))
colnames(freq)[1] = "word"
IDF = as.data.frame(left_join(IDF_words, freq, by = "word"))
num_tweets = dim(data)[1]
TF_IDF_temp = right_join(TF_words, IDF, by = "word")
TF_IDF = TF_IDF_temp
TF_IDF = cbind.data.frame(TF_IDF_temp$index.x, TF_IDF_temp$emotion.x, TF_IDF_temp$word, stringsAsFactors = FALSE)
colnames(TF_IDF) = c("index", "emotion", "word")
TF_IDF$emotion[TF_IDF$emotion == "Negative emotion"] = 0
TF_IDF$emotion[TF_IDF$emotion == "Positive emotion"] = 1
TF_IDF$TF = (TF_IDF_temp$count_per_tweet/TF_IDF_temp$num_words)
TF_IDF$IDF = log(num_tweets/TF_IDF_temp$Freq)
TF_IDF$TF_IDF = TF_IDF$TF * TF_IDF$IDF
test = TF_IDF[TF_IDF$IDF > 3.37,]
weighted_model = as.data.frame(TF_IDF[order(TF_IDF$index), ])
weighted_model = weighted_model %>%
group_by(test = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
detach("package:plyr"
detach("package:plyr")
weighted_model = as.data.frame(TF_IDF[order(TF_IDF$index), ])
weighted_model = weighted_model %>%
group_by(test = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF))
data_size = dim(weighted_model)[1]
dim(weighted_model)[1]
data_size = dim(weighted_model)[1]
train_size = floor(data_size * .7)
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
pred = predict(svmradi,dat[-train,])
table(predict = pred, truth = dat[-train,]$y)
(533+35)/(12+83+533+35)
tune.out = tune(svm,y~., data=dat[train,], kernel="radial", ranges = list(cost=10^(-1:1),gamma=c(0.5,1:4)))
best = tune.out$best.model
plot(best,dat[train,])
pred = predict(best,dat[-train,])
table(predict = pred, truth = dat[-train,]$y)
source('~/GitHub/Sentiment-Analysis/SentimentAnalysis.R')
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
# Predict with radial
pred = predict(svmradi,dat[-train,])
table(predict = pred, truth = dat[-train,]$y)
# Choose training set
data_size = dim(weighted_model)[1]
train_size = floor(data_size * .7)
dat = data.frame(x=cbind(weighted_model$TF, weighted_model$IDF), y=as.factor(weighted_model$emotion))
train = sample(data_size,train_size)
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
View(weighted_model)
View(TF_IDF)
# Remove overly common words
TF_IDF = TF_IDF[TF_IDF$IDF > 3.37,]
# Aggregate by index
detach("package:plyr")
weighted_model = as.data.frame(TF_IDF[order(TF_IDF$index), ])
weighted_model = weighted_model %>%
group_by(test = index %/% 1) %>%
summarize(TF = sum(TF), IDF = sum(IDF), TF_IDF = sum(TF_IDF), emotion = emotion[1])
# Choose training set
data_size = dim(weighted_model)[1]
train_size = floor(data_size * .7)
dat = data.frame(x=cbind(weighted_model$TF, weighted_model$IDF), y=as.factor(weighted_model$emotion))
train = sample(data_size,train_size)
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
# Predict with radial
pred = predict(svmradi,dat[-train,])
table(predict = pred, truth = dat[-train,]$y)
dat = data.frame(x=cbind(weighted_model$TF, weighted_model$TF_IDF), y=as.factor(weighted_model$emotion))
train = sample(data_size,train_size)
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
dat = data.frame(x=cbind(weighted_model$IDF, weighted_model$TF_IDF), y=as.factor(weighted_model$emotion))
train = sample(data_size,train_size)
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
# Predict with radial
pred = predict(svmradi,dat[-train,])
table(predict = pred, truth = dat[-train,]$y)
dat = data.frame(x=cbind(weighted_model$TF_IDF), y=as.factor(weighted_model$emotion))
train = sample(data_size,train_size)
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
dat = data.frame(x=cbind(weighted_model$TF, weighted_model$IDF), y=as.factor(weighted_model$emotion))
train = sample(data_size,train_size)
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmradi, dat[train,])
# Tune radial model
tune.out = tune(svm,y~., data=dat[train,], kernel="radial", ranges = list(cost=10^(-1:2),gamma=c(0.5,1:4)))
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=100)
plot(svmradi, dat[train,])
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1000)
# Radial
svmradi = svm(y~.,data=dat[train,], kernel="radial", gamma=1, cost=1000)
plot(svmradi, dat[train,])
# Predict with radial
pred = predict(svmradi,dat[-train,])
table(predict = pred, truth = dat[-train,]$y)
891/(891+170)
